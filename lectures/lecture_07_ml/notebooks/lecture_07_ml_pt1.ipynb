{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T17:58:47.264828Z",
     "start_time": "2019-10-31T17:58:47.260260Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формальная постановка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T09:44:35.143558Z",
     "start_time": "2019-10-31T09:44:35.139440Z"
    }
   },
   "source": [
    "<table><tr>\n",
    "<td><img src=\"images_pt1/class1.png\" style=\"height:400px\"></td>\n",
    "<td><img src=\"images_pt1/class2.png\" style=\"height:400px\"></td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дан набор обучающих примеров $$(x_1, x_2, \\dots, x_n), x_i \\in \\mathcal{X} \\subseteq \\mathbb{R}^k,$$ $n$ -- размер выборки, $k$ -- количество признаков (фичей). Также задан набор целевых переменных $$(y_1, y_2, \\dots, y_n), y_i \\in \\mathcal{Y} \\subseteq \\mathbb{R}.$$\n",
    "\n",
    "Наша задача построить алгоритм\n",
    "$$a: \\mathcal{X} \\to \\mathcal{Y},$$\n",
    "который будет приближать исходную зависимость $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача классификации\n",
    "Множество $\\mathcal{Y}$ конечно.\n",
    "\n",
    "Частный случай -- бинарная классификация ($|\\mathcal{Y}| = 2$), например, предсказываем будет ли клик, покупка. Будем пока рассматривать именно такие случаи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images_pt1/class3.png\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам надо найти уравнение прямой (гиперплоскости), которая бы могла разделить два класса ($H_2$ и $H_3$ подходят). В данном случае, уравнение прямой задаётся как: $$g(x) = w_0 + w_1x[1] + w_2x[2] = \\langle w, x \\rangle + w_0 =  w^\\top x + w_0$$\n",
    "\n",
    "* Если $g(x^*) > 0$, то $y^* = \\text{'черный'} = 1$\n",
    "* Если $g(x^*) < 0$, то $y^* = \\text{'белый'} = 0$\n",
    "* Если $g(x^*) = 0$, то мы находимся на линии\n",
    "* т.е. решающее правило: $y^* = \n",
    "\\begin{cases}\n",
    "1, &\\text{если } g(x^*) > 0,\\\\\n",
    "0, &\\text{если } g(x^*) < 0.\n",
    "\\end{cases}$\n",
    "\n",
    "Некоторые геометрические особенности\n",
    "* $\\frac{w_0}{||w||}$ - расстояние от начала координат то прямой\n",
    "* $\\frac{|g(x)|}{||w||}$ - расстояние от точки $x$ до гиперплоскости, степень \"уверенности\" в классификациий\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично! Значит нам надо просто минимизировать ошибки классификации для всех объектов:\n",
    "\n",
    "$$L(w) = \\sum_{i: y_i = 0} [g(x_i) > 0] + \\sum_{i: y_i = 1} [g(x_i) < 0] \\rightarrow \\min_w$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема в том, что это будет комбинаторная оптимизация. Существуют различные аппроксимации этой функции ошибок:\n",
    "<center><img src='http://jaquesgrobler.github.io/Online-Scikit-Learn-stat-tut/_images/plot_sgd_loss_functions_11.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим функцию $$\\sigma(z) = \\frac{1}{1 + exp{(-z)}},$$она называется **сигмойда**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T17:58:47.456210Z",
     "start_time": "2019-10-31T17:58:47.267774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def demo_sigmoid():\n",
    "    z = np.linspace(-10, 10, 100)\n",
    "\n",
    "    y = sigmoid(z)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(z, y)\n",
    "    plt.xlabel('$z$')\n",
    "    plt.ylabel('$\\sigma(z)$')\n",
    "    \n",
    "def sigmoid(z): \n",
    "    return 1./(1+np.exp(-z))\n",
    "demo_sigmoid() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images_pt1/prob.png\" style=\"height:500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Постановка задачи\n",
    "Будем требовать, чтобы алгоритм возвращал вероятность класса $y=1$:\n",
    "$$h(x,w) = p(y=1|x,w) = \\sigma(g(x))$$\n",
    "\n",
    "Выпишем функцию правдоподобия\n",
    "$$ \\mathcal{L}(w) = \\prod_{i=1}^n h(x_i,w)^{[y_i = 1]} (1 - h(x_i,w))^{[y_i = 0]} \\rightarrow \\max_w$$\n",
    "$$ -\\log{\\mathcal{L}(w)} = - \\sum_i^n [y_i = 1]\\cdot\\log{(h(x_i,w))} + {[y_i = 0]}\\cdot\\log{(1-h(x_i,w))} \\rightarrow \\min_w$$\n",
    "$$L(w) = -\\log{\\mathcal{L}(w)} \\rightarrow \\min_w $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм $h$ называется ***логистической регрессией***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из основных функций потерь -- ***Log Loss*** (бинарная классификация), которую мы получили при выводе логрегрессии:\n",
    "$$L = -\\sum_{i=1}^n(\\,\\,y_i \\cdot \\log{a(x_i)} + (1 - y_i) \\cdot \\log(1 - a(x_i))\\,\\,).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случай нескольких классов (>2)\n",
    "\n",
    "* А если классов несколько?\n",
    "    * 1-vs-1\n",
    "    * 1-vs-rest\n",
    "    * Softmax "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "\n",
    "Для каждого класса определяется свой набор весов\n",
    "$$\n",
    "\\begin{cases}\n",
    "g_1(x)=w_{1}^{T}x + w_{0,1} \\\\\n",
    "g_{2}(x)=w_{2}^{T}x + w_{0,2}\\\\\n",
    "\\cdots\\\\\n",
    "g_{C}(x)=w_{C}^{T}x + + w_{0,C}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Нормировка \"скоров\" классов\n",
    "\n",
    "$$\n",
    "p(y=c|x)=softmax(g_c|W, x)=\\frac{exp(w_{c}^{T}x + w_{0,c})}{\\sum_{i}exp(w_{i}^{T}x + w_{0,i})}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cross Entropy Loss*** (общий случай Log Loss), который мы можем вывести по аналогии с Log Loss:\n",
    "$$L = -\\sum_{i=1}^n <y_i , \\log{a(x_i)}>.$$\n",
    "\n",
    "Здесь $y_i$ и $a(x_i)$ -- вектора размерности $|\\mathcal{Y}|$, у $y_i$ только в одной позиции 1, в остальных -- 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод ближайших соседей\n",
    "\n",
    "### K-Nearest Neighbours\n",
    "\n",
    "$$\n",
    "h(x) = \\frac{1}{n} \\sum_{x_j \\in N_K(x)} f(x_j).\n",
    "$$\n",
    "\n",
    "$N_K(\\mathbf{x})$ -- $K$ ближайших соседей для вектора $x$ в обучающем наборе (то есть среди $x_1, ... , x_n$).\n",
    "\n",
    "Как можно использовать для бинарной классификации? А когда классов > 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Байесовский наивный классификатор (Naive Bayes)\n",
    "\n",
    "Дано\n",
    "\n",
    "$x \\in \\mathcal{X}$ - вектор признаков. Наивность алгоритма характеризуется предположением о том, что компоненты вектора $x$ являются **независимыми** между собой случайными величинами.\n",
    "\n",
    "$C_k \\in \\mathcal{Y}, \\; k = 1,\\ldots,|\\mathcal{Y}|$ - целевая переменная.\n",
    "\n",
    "Теорема Байеса\n",
    "$$\n",
    "P(C_k \\mid x) = \\frac{p(x \\mid C_k) p(C_k)}{p(x)} \\propto p(x \\mid C_k) p(C_k).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из независимости компонент $x$:\n",
    "$$p(x \\mid C_k) = \\prod_j p_j(x[j] \\mid C_k).$$\n",
    "\n",
    "Таким образом обучение состоит в оценке плотностей $p_j(x[j] \\mid C_k), p(C_k)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказание производится с помощью принципа Maximum A-Posteriori:\n",
    "$$\n",
    "C_{MAP} = \\arg \\max_k p(C_k \\mid x) = \\arg \\max_k p(C_k)\\prod_j p_j(x[j] \\mid C_k).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Байесовский классификатор — широкий класс алгоритмов классификации, основанный на принципе максимума апостериорной вероятности.  \n",
    "Для классифицируемого объекта вычисляются функции правдоподобия каждого из классов, по ним вычисляются апостериорные вероятности классов.  \n",
    "Объект относится к тому классу, для которого апостериорная вероятность максимальна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "|d | Текст | Класс |\n",
    "|--|--|--|\n",
    "|1 | котики такие мокрые | мимими |\n",
    "|2 | пушистые котики няшки | мимими |\n",
    "|3 | морские котики  | не мимими |\n",
    "|4 | мокрые морские свинки | не мимими |\n",
    "|5 | котики мокрые | ???|\n",
    "\n",
    "С помощью алгоритма MultinomialNB (считаем токены) вычислить $p(\\text{мимими} | d_5)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что еще есть: SVM, SVM + kernel trick, Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td><img src=\"images_pt1/prec1.png\" style=\"height:400px\"></td>\n",
    "<td><img src=\"images_pt1/prec2.png\" style=\"height:400px\"></td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Accuracy = \\frac{1}{n}\\sum_{i=1}^n [a(x_i) = y_i]$$\n",
    "\n",
    "$$Precision = \\sum_{i=1}^n \\frac{[a(x_i) = y_i = 1]}{[a(x_i) = 1]}$$\n",
    "\n",
    "$$Recall = \\sum_{i=1}^n \\frac{[a(x_i) = y_i = 1]}{[y_i = 1]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F мера\n",
    "\n",
    "$$F1 = 2 \\cdot \\frac{Recall \\cdot Precision}{Recall + Precision}.$$\n",
    "\n",
    "$$F_\\beta = (1 + \\beta^2) \\cdot \\frac{Recall \\cdot Precision}{Recall + \\beta^2 \\cdot Precision}.$$\n",
    "\n",
    "$$F_\\beta = \\left({\\frac {\\alpha }{Precision}}+{\\frac {1-\\alpha }{Recall}}\\right)^{-1}, \\,\\,\n",
    "\\alpha ={\\frac {1}{1+\\beta ^{2}}}.$$\n",
    "\n",
    "`Measures the effectiveness of retrieval with respect to a user who attaches β times as much importance to recall as precision.` ([wiki](https://en.wikipedia.org/wiki/F1_score))\n",
    "\n",
    "При $\\beta \\to \\infty$ получаем $F_\\beta \\to Recall$.\n",
    "\n",
    "При $\\beta \\to 0$ получаем $F_\\beta \\to Precision$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC-AUC\n",
    "\n",
    "Для задачи бинарной классификации алгоритм $a$ может выдавать не просто метку из $\\mathcal{Y}$, а некоторое число (скор, вероятность). Чтобы сказать какая метка будет на выходе алгоритма используют порог $\\alpha$ так, что:\n",
    "\n",
    "$$\\hat{y}_i =\n",
    "\t \\begin{cases}{}\n",
    "\t \t1, &\\text{если } a(x_i) \\geq \\alpha, \\\\\n",
    "\t \t0, &\\text{если } a(x_i) < \\alpha.\n",
    "\t \\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images_pt1/tp_fp.png\" style=\"height:300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В зависимости от этого порога у нас будут получаться разные предсказания на одних и тех же данных. Следовательно и метрики качества будут разные. Определим следующие величины:\n",
    "\n",
    "$$TPR = \\frac{TP}{TP+FN}, \\,\\, FPR = \\frac{FP}{FP+TN}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для разных значений порога $-\\infty < \\alpha < +\\infty$ посчитает значения TPR и FPR и отложим их на графике:\n",
    "\n",
    "<img src=\"images_pt1/roc_auc.png\" style=\"height:400px\">\n",
    "\n",
    "Площадь под графиком и является метрикой ROC-AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Интерпретация через непрерывные случайные величины:\n",
    "\n",
    "<img src=\"images_pt1/roc_auc_interpret.png\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PR-AUC\n",
    "По аналогии с ROC-AUC, только по осям у нас Precision и Recall.\n",
    "\n",
    "<img src=\"images_pt1/pr_auc.png\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что еще может быть: KL divergence, margin loss и много других..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images_pt1/class3.png\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уравнение прямой задаётся как: $$g(x) = w_0 + w_1x_1 + w_2x_2 = w_0 + \\langle w, x \\rangle = w_0 +  w^\\top x $$\n",
    "\n",
    "* Если $g(x^*) > 0$, то $y^* = \\text{'черный'} = +1$\n",
    "* Если $g(x^*) < 0$, то $y^* = \\text{'белый'} = -1$ (немного поменяем обозначения для простоты изложения)\n",
    "* Если $g(x^*) = 0$, то мы находимся на линии\n",
    "* т.е. решающее правило: $y^* = sign(g(x^*))$\n",
    "\n",
    "Некоторые геометрические особенности\n",
    "* $\\frac{|g(x)|}{||w||}$ - расстояние от точки $x$ до гиперплоскости, степень \"уверенности\" в классификациий\n",
    "* Величину $M = y(\\langle w, x \\rangle + w_0) = y \\cdot g(x)$ называют **отступом**(margin)\n",
    "\n",
    "Если для какого-то объекта $M \\geq 0$, то его классификация выполнена успешно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Линейноразделимый случай с двумя классами\n",
    "* Заметим что $g(x) = w_0 + \\langle w, x \\rangle$ и $g'(x) = c \\cdot (w_0 + \\langle w, x \\rangle)$, $\\forall c>0$ задают одну и ту же гиперплоскость\n",
    "* Подберем $c$ таким образом, чтобы $\\min\\limits_i M_i = \\min\\limits_i y \\cdot g(x_i) = 1$\n",
    "\n",
    "<center><img src='./images_pt1/margin.png'></center>\n",
    "\n",
    "* Таким образом выполняются следующие неравенства:\n",
    "    * $w_0 + \\langle w, x_i \\rangle \\geq 1$, если $y_i = + 1$\n",
    "    * $w_0 + \\langle w, x_i \\rangle \\leq - 1$, если $y_i = - 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Разделяющая полоса:  $ -1 \\leq w_0 + \\langle w, x \\rangle \\leq +1$\n",
    "* Ширина разделяющей полосы:\n",
    " $$\\langle (x_{+} -  x_{-}) , \\frac{w}{||w||}\\rangle = \\frac{\\langle w, x_{+} \\rangle - \\langle w, x_{-} \\rangle }{||w||} = \\frac{2}{||w||}  \\rightarrow \\max$$\n",
    " \n",
    " \n",
    "* Таким образом мы придем к оптимизационной задаче:\n",
    "$$\n",
    "\\begin{cases} \n",
    "   \\frac{1}{2} ||w||^2  \\rightarrow \\min  \\\\\n",
    "   y^{(i)}(\\langle w, x^{(i)} \\rangle + w_0 ) \\geq 1 \\quad i=1\\dots n\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По теореме Куна-Таккера:\n",
    "\n",
    "\n",
    "$$\\begin{cases} \n",
    "   \\mathcal{L}(w,w_0,\\lambda) = \\frac{1}{2} ||w||^2  - \\sum\\limits_i \\lambda_i \\left( y^{(i)}(\\langle w, x \\rangle + w_0 )  - 1\\right)  \\rightarrow \\min\\limits_{w,w_0}\\max\\limits_{\\lambda}  \\\\\n",
    "   \\lambda_i \\geq 0 \\quad i=1\\dots n\\\\\n",
    "   \\lambda_i = 0 \\text{, либо }  \\langle w, x^{(i)} \\rangle + w_0 = y^{(i)} \\quad i=1\\dots n\n",
    "\\end{cases}$$\n",
    "Объекты, для которых  $\\lambda_i \\neq 0$ называются ** опорными ** \n",
    "\n",
    "\n",
    "Необходимое условие:\n",
    "*  $\\frac{\\partial \\mathcal{L} }{\\partial w} = w - \\sum\\limits_i \\lambda_iy_ix_i = 0 \\quad \\Rightarrow  \\quad w = \\sum\\limits_i \\lambda_iy_ix_i$\n",
    "*  $\\frac{\\partial \\mathcal{L} }{\\partial w_0} = \\sum\\limits_i \\lambda_iy_i = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Сопряжённая задача) Если подставить  эти результаты в $\\mathcal{L}$ то получится\n",
    "$$\\begin{cases}\n",
    "\\mathcal{L}(\\lambda) = \\sum\\limits_i\\lambda_i  - \\frac{1}{2} \\sum\\limits_i\\sum\\limits_j \\lambda_i \\lambda_j  y_i y_j (\\langle x_i, x_j \\rangle)  \\rightarrow \\max\\limits_\\lambda  \\\\\n",
    "\\lambda_i \\geq 0 \\quad i=1\\dots n \\\\\n",
    "\\sum\\limits_i \\lambda_iy_i = 0\n",
    "\\end{cases}$$\n",
    "\n",
    "* **Зависит не от самих объектов, а от их скалярного произведения! **\n",
    "* $\\mathcal{L}(\\lambda)$ - выпуклая и ограниченная сверху функция.\n",
    "* Имеем единственное решение при линейной разделимости\n",
    "* Находим $\\lambda_i,$ из $w = \\sum\\limits_i \\lambda_iy_ix_i$ находим коэффициенты $w$.\n",
    "* Свободный член $w_0$ определяется как среднее или медиана $\\{\\langle w, x_i \\rangle - y_i: \\lambda_i \\neq 0\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T17:58:47.476263Z",
     "start_time": "2019-10-31T17:58:47.459509Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_classification\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,5)\n",
    "\n",
    "# Для кириллицы на графиках\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "try:\n",
    "    from ipywidgets import interact, IntSlider, fixed, FloatSlider\n",
    "except ImportError:\n",
    "    print('Так надо')\n",
    "\n",
    "def plot_svc_log_decision_function(clf1, clf2, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    x = np.linspace(plt.xlim()[0], plt.xlim()[1], 30)\n",
    "    y = np.linspace(plt.ylim()[0], plt.ylim()[1], 30)\n",
    "    XX, YY = np.meshgrid(x, y)\n",
    "    XY = np.c_[XX.ravel(), YY.ravel()]\n",
    "    P1 = clf1.decision_function(XY)\n",
    "    P1 = P1.reshape(XX.shape)\n",
    "    \n",
    "    P2 = clf2.decision_function(XY)\n",
    "    P2 = P2.reshape(XX.shape)\n",
    "    # plot the margins\n",
    "    cplot = ax.contour(XX, YY, P1, colors='k', label='svm',\n",
    "               levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "    ax.clabel(cplot, inline=1, fontsize=10)\n",
    "    \n",
    "    ax.contour(XX, YY, P2, colors='r', label='logreg',\n",
    "               levels=[0], alpha=0.5,\n",
    "               linestyles=['-'])\n",
    "\n",
    "    \n",
    "def plot_svc_decision_function(clf1, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    x = np.linspace(plt.xlim()[0], plt.xlim()[1], 30)\n",
    "    y = np.linspace(plt.ylim()[0], plt.ylim()[1], 30)\n",
    "    XX, YY = np.meshgrid(x, y)\n",
    "    XY = np.c_[XX.ravel(), YY.ravel()]\n",
    "    P1 = clf1.decision_function(XY)\n",
    "    P1 = P1.reshape(XX.shape)\n",
    "    \n",
    "    # plot the margins\n",
    "    cplot = ax.contour(XX, YY, P1, colors='k', label='svm',\n",
    "               levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "    ax.clabel(cplot, inline=1, fontsize=10)\n",
    "    \n",
    "\n",
    "def lin_sep_svm_demo(class_sep=2):\n",
    "    X, y = make_classification(n_samples=100, n_features=2, n_informative=2, class_sep=class_sep, scale=1,\n",
    "                                n_redundant=0, n_clusters_per_class=1, random_state=31)\n",
    "    # x_line = np.linspace(np.min(X) - 0.5, np.max(X) + 0.5)\n",
    "\n",
    "    lin_svm = SVC(kernel='linear', C=100).fit(X, y)\n",
    "    \n",
    "    log_reg = LogisticRegression(C=100).fit(X, y)\n",
    "    \n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=70, cmap='autumn')\n",
    "    plot_svc_log_decision_function(lin_svm, log_reg)\n",
    "    # plt.scatter(lin_svm.support_vectors_[:, 0], lin_svm.support_vectors_[:, 1],\n",
    "    #        s=200, facecolors='none')\n",
    "    \n",
    "    \n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('$x_2$')\n",
    "    \n",
    "    plt.xlim(-2, 5)\n",
    "    plt.ylim(-3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T17:58:47.738635Z",
     "start_time": "2019-10-31T17:58:47.478555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7b5a1bd1a940038102db8830965921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=2.0, description='class_sep', max=4.0, min=0.4), Output()), _dom_class…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.lin_sep_svm_demo(class_sep=2)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(lin_sep_svm_demo, class_sep=FloatSlider(min=0.4, max=4, step=0.1, value=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Неразделимый случай \n",
    "\n",
    "Будем допускать пропуск объектов за разделительную линию\n",
    "* Вместо условия $y^{(i)}(\\langle w, x^{(i)} \\rangle + w_0 ) \\geq 1$\n",
    "* Будет условие $y^{(i)}(\\langle w, x^{(i)} \\rangle + w_0 ) \\geq 1 - \\xi_i, \\quad \\xi_i \\geq 0$\n",
    "\n",
    "<center><img src='./images_pt1/slack.png'></center>\n",
    "\n",
    "А целевой функционал заменим на \n",
    "\n",
    "$$ \\frac{1}{2} ||w||^2 + C\\sum\\limits_i\\xi_i  \\rightarrow \\min\\limits_{w,w_0,\\xi}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом мы придем к оптимизационной задаче:\n",
    "$$\n",
    "\\begin{cases} \n",
    "   \\frac{1}{2} ||w||^2 + C\\sum\\limits_i\\xi_i  \\rightarrow \\min\\limits_{w,w_0,\\xi} \\\\\n",
    "   y^{(i)}(\\langle w, x^{(i)} \\rangle + w_0 ) \\geq 1 - \\xi_i \\quad i=1\\dots n \\\\\n",
    "   \\xi_i \\geq 0 \\quad i=1\\dots n\n",
    "\\end{cases}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Условия Куна-Таккера, необходимые условия оптимума $\\rightarrow$ получаем сопряженную задачу\n",
    "$$\\begin{cases}\n",
    "\\mathcal{L}(\\lambda) = \\sum\\limits_i\\lambda_i  - \\frac{1}{2} \\sum\\limits_i\\sum\\limits_j \\lambda_i \\lambda_j  y_i y_j (\\langle x_i, x_j \\rangle)  \\rightarrow \\max\\limits_\\lambda  \\\\\n",
    "0 \\leq \\lambda_i \\leq C \\quad i=1\\dots n \\\\\n",
    "\\sum\\limits_i \\lambda_iy_i = 0\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что изначальный целевой функционал\n",
    "$$ \\frac{1}{2} ||w||^2 + C\\sum\\limits_i\\xi_i  \\rightarrow \\min\\limits_{w,w_0,\\xi}  $$\n",
    "Можно представить в виде\n",
    "$$ \\frac{1}{2С} ||w||^2 + \\sum\\limits_i(1-M_i)_+ \\rightarrow \\min\\limits_{w,w_0}, $$\n",
    "где $M_i$ - это отступ объекта  $x^{(i)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T17:58:47.749720Z",
     "start_time": "2019-10-31T17:58:47.742588Z"
    }
   },
   "outputs": [],
   "source": [
    "def lin_sep_svm_demo_C(class_sep=2, C=10):\n",
    "    X, y = make_classification(n_samples=100, n_features=2, n_informative=2, class_sep=class_sep, scale=1,\n",
    "                                n_redundant=0, n_clusters_per_class=1, random_state=31)\n",
    "    # x_line = np.linspace(np.min(X) - 0.5, np.max(X) + 0.5)\n",
    "\n",
    "    lin_svm = SVC(kernel='linear', C=C).fit(X, y)\n",
    "    \n",
    "    log_reg = LogisticRegression(C=C).fit(X, y)\n",
    "    \n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=70, cmap='autumn')\n",
    "    plot_svc_log_decision_function(lin_svm, log_reg)\n",
    "    plt.scatter(lin_svm.support_vectors_[:, 0], lin_svm.support_vectors_[:, 1],\n",
    "            s=200, facecolors='none')\n",
    "    \n",
    "    \n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('$x_2$')\n",
    "    \n",
    "    plt.xlim(-2, 5)\n",
    "    plt.ylim(-3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T17:58:47.976576Z",
     "start_time": "2019-10-31T17:58:47.751425Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f8401e8b5e4814a330d71bc3c4847f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=2.0, description='class_sep', max=4.0, min=0.2, step=0.2), FloatSlider…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.lin_sep_svm_demo_C(class_sep=2, C=10)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(lin_sep_svm_demo_C, class_sep=FloatSlider(min=0.2, max=4, value=2, step=0.2), C=FloatSlider(min=0.002, max=10, step=0.002, value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще есть kernel trick -- делаем преобразование пространства так, что в новом пространстве классы линейно разделимы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
